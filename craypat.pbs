#!/bin/bash --login

#PBS -N craypat_profile
#PBS -l select=1
#PBS -l walltime=0:20:0
#PBS -A ecse0506

# Test configuration is good and longer jobs can be run no problem by submitting to the
# short queue that runs jobs earlier. Remember 20 min time limit, and only Mon-Fri 9am-5pm
# qsub -q short <path_to_this_file>

# Set up a few variables to pass to aprun
NODES=1
SUFFIX=`date +"%Y%m%d_%H%M%S"`
OUTPUT_DIR=$WORK/output/craypat/$SUFFIX
LOGFILE=$OUTPUT_DIR/craypat
mkdir -p $OUTPUT_DIR

# Make sure any symbolic links are resolved to absolute path
export PBS_O_WORKDIR=$(readlink -f $PBS_O_WORKDIR)

# The base directory is the directory that the job was submitted from.
# All simulations are in subdirectories of this directory.
basedir=$PBS_O_WORKDIR

# This shifts to the directory that you submitted the job from
cd $basedir

#Load all the necessary tools and set the work environment
source $WORK/HJCFIT/utils/archer/loadArcherModules.sh

# Load virtual env
source activate dcprogs

# Add virtual env path to LD_LIBRARY_PATH, otherwise it complains about not finding liblikelihood.so
export LD_LIBRARY_PATH=$CONDA_ENV_PATH/lib:$LD_LIBRARY_PATH

# Profile exploration data with 1 to 24 nodes. Time for each execution will be
# outputted from the python code
threads=1
echo "Executing fitGlyR4 with $threads threads in $NODES node/s. "
export OMP_NUM_THREADS=$threads
aprun -n $NODES -d $threads build/log10long+samp

# Exit virtual env
source deactivate
